Assignment 2: Netflix Data Wrangling
Completion requirements
Opened: Tuesday, 20 May 2025, 12:00 AM
Due: Monday, 26 May 2025, 11:59 PM
Overview
This week’s assignment will develop hands-on experience automating web data gathering using Kaggle Data Set and publishing your work on Kaggle.

You are required to practice the Data Wrangling concepts to clean up the Netflix dataset available on Kaggle

Link:  https://www.kaggle.com/datasets/shivamb/netflix-shows

The objectives of the assignment are to:

Load the Netflix dataset from a CSV file and explore its structure using pandas.
Perform data discovery to assess data types, missing values, and quality issues.
Clean the dataset by handling duplicates, missing values, and formatting inconsistencies.
Transform and enrich the dataset using techniques like filtering, sorting, grouping, and feature extraction.
Validate the final dataset by checking consistency, completeness, and logical accuracy.
Export the final cleaned dataset to a .csv file ready for analysis or visualization.
Sample Code 
'''
  Title: Data Wrangling Project
  Name: Paula Musuva
  Date: 20 May 2025
  You can write a few comments about your project
'''
#Import the Data to a Pandas DataFrame
df = pd.read_csv('/kaggle/input/netflix/netflix_titles.csv')

1. Discovery
#Have a quick overview of the data
df.info()
# Number of rows and columns
print("Shape of the dataset (R x C):", df.shape)
# List of all column names
print("Columns in the dataset:\n", df.columns.tolist())
# Data types of each column
print("Data types:\n", df.dtypes)
# Group and Count of missing (null) values in each column
print("Missing values per column:\n", df.isnull().sum())
# Group and Count of duplicate rows
print("Number of duplicate rows:", df.duplicated().sum())

2. Structuring
# Convert 'date_added' to datetime
df['date_added'] = pd.to_datetime(df['date_added'],format='mixed')

# Separate 'duration' into numeric value and unit (e.g., '90 min' → 90, 'min')
df[['duration_value', 'duration_unit']] = df['duration'].str.extract(r'(\d+)\s*(\w+)')

# Convert duration_value to numeric
df['duration_value'] = pd.to_numeric(df['duration_value'])

# View Resulting columns
print(df[['duration_value', 'duration_unit']])

Consider other ways you can structure and format the other columns

3. Cleaning
# Check for duplicate rows
print("Duplicate rows before:", df.duplicated().sum())

# Drop duplicate rows if any
df = df.drop_duplicates()

# Drop description column because it will not be used
df = df.drop(columns=['description'])

# Impute Director values by using relationship between cast and director

# List of Director-Cast pairs and the number of times they appear
df['dir_cast'] = df['director'] + '---' + df['cast']
counts = df['dir_cast'].value_counts() #counts unique values
filtered_counts = counts[counts >= 3] #checks if repeated 3 or more times
filtered_values = filtered_counts.index #gets the values i.e. names
lst_dir_cast = list(filtered_values) #convert to list
dict_direcast = dict()
for i in lst_dir_cast :
     director,cast = i.split('---’)
    dict_direcast[director]=cast
for i in range(len(dict_direcast)): 
    df.loc[(df['director'].isna()) & (df['cast'] == list(dict_direcast.items())[i][1]),'director'] = list(dict_direcast.items())[i][0]

# Assign Not Given to all other director fields
df.loc[df['director'].isna(),'director'] = 'Not Given’

#Use directors to fill missing countries
directors = df['director’]
countries = df['country’]
#pair each director with their country use zip() to get an iterator of tuples
pairs = zip(directors, countries)
# Convert the list of tuples into a dictionary
dir_cntry = dict(list(pairs))

# Director matched to Country values used to fill in null country values
for i in range(len(dir_cntry)):    
df.loc[(df['country'].isna()) & (df['director'] == list(dir_cntry.items())[i][0]),'country'] = list(dir_cntry.items())[i][1]
# Assign Not Given to all other country fields
df.loc[df['country'].isna(),'country'] = 'Not Given'

# Assign Not Given to all other fields
df.loc[df[‘cast'].isna(),’cast'] = 'Not Given'

# dropping other row records that are null
df.drop(df[df['date_added'].isna()].index,axis=0,inplace=True)
df.drop(df[df['rating'].isna()].index,axis=0,inplace=True)
df.drop(df[df['duration'].isna()].index,axis=0,inplace=True)

Errors
# check if there are any added_dates that come before release_year
import datetime as dt
sum(df['date_added'].dt.year < df['release_year’])
df.loc[(df['date_added'].dt.year < df['release_year']),['date_added','release_year’]]
# sample some of the records and check that they have been accurately replaced
df.iloc[[1551,1696,2920,3168]]
#Confirm that no more release_year inconsistencies
sum(df['date_added'].dt.year < df['release_year'])

Validate
Remove any columns you may have added during wrangling e.g.
df.drop(columns=['dir_cast'], inplace=True)
Check the consistency, accuracy, and completeness of the data
Ensure each column has the correct data type e.g. verify that date_added is datetime and duration_value is numeric.
Use business logic or sanity rules to identify anomalies e.g. records before 1997
Ensure no important fields are still missing
Sample a few rows to check visually e.g. df.sample(5)
Reset the Index e.g. df_reset = df.reset_index(drop=True)
Publish
# Save as CSV 
df.to_csv('/kaggle/working/cleaned_netflix.csv', index=False)

Submission Guidelines
Write a report with a cover page that captures your name and program details, followed by an Introduction, Task Completion and Conclusion Sections.

As you complete your tasks, provide evidence of completion by capturing screenshots with sufficient detail. 

Ensure your write-ups and screenshots demonstrate enough detail to confirm your engagement in completing the lab assignment.

Ensure to follow good coding practices by using appropriate names for variables, using comments and white space for code readability.

Share a link to your final Notebook by clicking the Share button on the top-right side of the page. Ensure you allow Public Access

Submit this report as a PDF for marking, and ensure it includes a link to your Notebook